# -*- coding: utf-8 -*-
"""Parkinson's Disease Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1WkMG1cBaZpLer67jXPeDqxI7kzo_WfzQ

Importing the dependencies (libraries):
"""

!pip install lux

import numpy as np
import lux
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score

"""Data Collection and Analysis:"""

# loading the data from csv file to a pandas dataframe
parkinsons_data = pd.read_csv('/content/parkinsons1.csv')

# printing the first five rows of the dataframe
parkinsons_data.head()

# for showing the lux visualization
from google.colab import output
output.enable_custom_widget_manager()

# number of rows and columns in the dataframe
parkinsons_data.shape

# getting more information about the dataset:
parkinsons_data.info()

# checking for missing values in each column
parkinsons_data.isnull().sum()

#getting some statistical measures about the data
parkinsons_data.describe()

# distibution of target(status) variable
parkinsons_data['status'].value_counts()

# grouping the data based on the target variable
parkinsons_data.groupby('status').mean()

"""Data Preprocessing:"""

# separating the features(other column) and traget column
x = parkinsons_data.drop(columns=['name','status'], axis=1)
y = parkinsons_data['status']

print(x)

print(y)

"""Splitting the data to training data & Teating data:"""

x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=2)

print(x.shape, x_train.shape, x_test.shape)

"""Data Standardization:"""

scaler = StandardScaler()

scaler.fit(x_train)

x_train = scaler.transform(x_train)

x_test = scaler.transform(x_test)

print(x_train)

"""Model Training: (Support Vector Machine Model)"""

model = svm.SVC(kernel='linear')

# training the svm model with training data
model.fit(x_train, y_train)

"""Model Evaluation:"""

# accuracy score on training data
x_train_prediction = model.predict(x_train)
training_data_accuracy = accuracy_score(y_train, x_train_prediction)

print('Accuracy score of training data: ',training_data_accuracy)

# accuracy score on testing data
x_test_prediction = model.predict(x_test)
test_data_accuracy = accuracy_score(y_test, x_test_prediction)

print('Accuracy score of testing data: ',test_data_accuracy)

"""Building a Predictive/Detective System:"""

input_data = (116.68200,131.11100,74.99700,0.00784,0.00007,0.00370,0.00554,0.01109,0.04374,0.42600,0.02182,0.03130,0.02971,0.06545,0.02211,21.03300,0.414783,0.815285,-4.813031,0.266482,2.301442,0.284654)

# changing the input data into numpy array
input_data_as_numpy_array = np.asarray(input_data)

# reshape the numpy array
input_data_reshaped = input_data_as_numpy_array.reshape(1, -1)

# standardize the data
std_data = scaler.transform(input_data_reshaped)

prediction = model.predict(std_data)
print(prediction)

if (prediction[0] == 0):
  print("Thwe Person does not have Parkinson's Disease")

else:
  print("The Person has Parkinson's Disease")

